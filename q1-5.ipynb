{
 "cells": [
  {
   "source": [
    "## Instructions {-}\n",
    "Ce sujet est constitu√© de deux parties : la partie 1 correspond au sujet donn√© l'an dernier, dont la correction vous est donn√©e, la partie 2 constitue la partie qui sera √©valu√©e et se place dans la continuit√© de la partie 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enonc√© du probl√®me (Partie 1)\n",
    "\n",
    "L'objectif de ce projet est d'estimer la longueur de c√¢ble sous-marin n√©cessaire pour relier deux c√¥tes $A$ et $B$  en utilisant des simulations conditionnelles.\n",
    "\n",
    "\n",
    "Le c√¢ble reposera sur le fond marin dont la profondeur est inconnue.\n",
    "Le segment $[AB]$ est discr√©tis√© par une s√©quence de (N+1) points. On pose $x_0=A$ et pour $i=1,\\dots,N$, $$x_i=x_0+i\\Delta$$ o√π $$\\Delta = \\frac{AB}{N}$$ de telle sorte que $x_N=B$.\n",
    "On note $z(x)$ la profondeur du fond marin au point $x$ de telle sorte \n",
    "qu'on pourra estimer la longueur totale de c√¢ble n√©cessaire par la somme \n",
    "des longueurs sur les segments de la discr√©tisation :\n",
    "\n",
    "$$l=\\sum_{i=1}^N\\sqrt{\\Delta^2+(z(x_i)-z(x_{i-1}))^2}.$$\n",
    "\n",
    "Enfin, notons que l'on dispose d'un ensemble de $n$ observations de la \n",
    "profondeur que l'on supposera situ√©es sur des points de discr√©tisation $z(x_{j_1}),\\dots,z(x_{j_n})$.\n",
    "\n",
    "\n",
    "On adopte un mod√®le probabiliste pour la profondeur. On suppose que le vecteur des \n",
    "profondeurs sur les points de discr√©tisation \n",
    "$\\mathbf{z}=(z(x_0),\\dots,z(x_N))$ est la r√©alisation\n",
    "d'un vecteur al√©atoire gaussien $\\mathbf{Z}=(Z(x_0),\\dots,Z(x_N))$ \n",
    "dont le vecteur d'esp√©rance ne contient qu'une seule valeur $\\mu$ \n",
    "r√©p√©t√©e $N+1$ fois et dont la matrice de covariance $\\Sigma$ a pour termes $\\sigma_{ij}$\n",
    "d√©finis par $\\sigma_{ij}=C(|x_i-x_j|)$ o√π $C$ est une\n",
    "fonction d√©croissante, traduisant le fait que deux points \n",
    "g√©ographiquement proches ont tendance √† avoir des profondeurs plus similaires que deux points √©loign√©s.\n",
    "\n",
    "On supposera que la matrice de covariance ainsi \n",
    "g√©n√©r√©e est d√©finie-positive (en fait, $C$ sera choisie parmi les fonctions qui, \n",
    "appliqu√©es aux termes d'une matrice de distance, produisent des matrices d√©finie-positives). \n",
    "\n",
    "Si on note $L$ la variable al√©atoire donnant la longueur de cable n√©cessaire : \n",
    "$$L=\\sum_{i=1}^N\\sqrt{\\Delta^2+(Z(x_i)-Z(x_{i-1}))^2},$$\n",
    "un bon estimateur de $L$ est fourni par l'esp√©rance conditionnelle \n",
    "\n",
    "$$L^\\star=E[L|Z(x_{j_1})=z(x_{j_1}),\\dots,Z(x_{j_n})=z(x_{j_n})].$$\n",
    "                                                                              \n",
    "Cependant, cette quantit√© est difficilement accessible par le calcul. \n",
    "On va donc avoir recours √† des\n",
    "simulations conditionnelles. C'est-√†-dire que l'on va simuler \n",
    "un nombre $K$ de r√©alit√©s (disons des r√©alisations du mod√®le \n",
    "probabiliste choisi), et sur chacune d'entre elle, \n",
    "la quantit√© de c√¢ble n√©cessaire sera √©valu√©e. \n",
    "On disposera ainsi d'un √©chantillon $l_{(1)},\\dots,l_{(K)}$ de \n",
    "longueures simul√©es. Puis on approchera l'esp√©rance conditionnelle  par \n",
    "$$L^\\star=\\frac1{K}\\sum_{k=1}^K l_{(k)}.$$\n",
    "\n",
    "L'objectif de ce projet est donc d'√©crire un code permettant \n",
    "d'effectuer cette simulation conditionnelle, puis de l'appliquer \n",
    "au jeu de donn√©es fourni et d'en d√©duire une estimation de la longueur de c√¢ble n√©cessaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions th√©oriques\n",
    "\n",
    "1. Quel th√©or√®me du cours nous autorise-t-il √† estimer l'esp√©rance conditionnelle par la moyenne empirique de simulations conditionnelles ?\n",
    "\n",
    "*la loi forte des grands nombres, cf [Proba IV p.16](https://boisgera.github.io/CDIS/output/Probabilit%C3%A9%20IV.pdf), en v√©rifiant que $L$ est bien int√©grable*\n",
    "\n",
    "2. Rappeler la loi conditionnelle du vecteur des composantes de $\\mathbf{Z}$ correspondant aux points de discr√©tisation\n",
    "sans observation, connaissant les valeurs prises par les composantes aux sites d'observation.\n",
    "\n",
    "*cf. [Proba III p.18](https://boisgera.github.io/CDIS/output/Probabilit%C3%A9%20III.pdf),*\n",
    "\n",
    "3. Si $\\mathbf{Y}=(Y_1,\\dots,Y_p)$ est un vecteur de composantes gaussiennes ind√©pendantes, toutes d'esp√©rance nulle et de variance 1, \n",
    "quelle est la loi du vecteur $\\mathbf{Z}=m+R\\mathbf{Y}$ o√π $R$ est une matrice $p\\times p$ et $m$ est un vecteur de taille $p$ ?\n",
    "\n",
    "*cf. [Proba V p.12](https://cloud.mines-paristech.fr/index.php/s/GLDwtTAMOJCYk3i/download)*\n",
    "\n",
    "4. En d√©duire un algorithme de simulation conditionnelle.\n",
    "\n",
    "*Appliquer l'algorithme de la q.3 √† la loi conditionnelle (on calculera en particulier l'esp√©rance conditionnelle de $\\mathbf{Z}$ sachant les donn√©es et la d√©composition de Cholesky de la matrice de covariance conditionnelle sachant les donn√©es).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Donn√©es du probl√®me\n",
    "Conventionnellement, $A$ est l'origine, $B=500$, $N=100$.\n",
    "\n",
    "Les donn√©es $$\\begin{array}{c|r}i & z(x_i)\\\\\n",
    "\\hline\n",
    "0 & 0\\\\\n",
    "20 & -4\\\\\n",
    "40 & -12.8\\\\\n",
    "60 & -1\\\\\n",
    "80 & -6.5\\\\\n",
    "100 & 0\\end{array}$$\n",
    "\n",
    "L'esp√©rance de chaque composante du vecteur al√©atoire $\\mathbf{Z}$ est donn√©e par $\\mu=-5.$\n",
    "\n",
    "La fonction $C$ est d√©finie par $$C(h)=\\sigma^2 e^{-|h|/a},$$\n",
    "\n",
    "o√π $|h|$ correspond √† la distance entre deux points, $a=50$ et $\\sigma^2=12$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impl√©mentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©ambule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement de d√©pendances\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Discr√©tisation\n",
    "A=0\n",
    "B=500\n",
    "N=101 #Nombre de points de discr√©tisation\n",
    "Delta = (B-A)/(N-1)\n",
    "discretization_indexes = np.arange(N)\n",
    "discretization = discretization_indexes*Delta\n",
    "#Param√®tres du mod√®le\n",
    "\n",
    "mu=-5\n",
    "a = 50\n",
    "sigma2 = 12\n",
    "\n",
    "#Donn√©es\n",
    "\n",
    "observation_indexes = [0,20,40,60,80,100]\n",
    "depth = np.array([0,-4,-12.8,-1,-6.5,0])\n",
    "\n",
    "#Indices des composantes correspondant aux observations et aux componsantes non observ√©es\n",
    "\n",
    "unknown_indexes=list(set(discretization_indexes)-set(observation_indexes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Ecrire une fonction qui prend en argument la distance entre les points, le param√®tre $a$, et le param√®tre $\\sigma^2$, et qui retourne la covariance entre deux points.\n",
    "On pourra fournir une matrice de distance √† cette fonction. Dans ce cas, la fonction renverra la matrice de covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction C\n",
    "\n",
    "def Covexp(dist,rangeval,sigmaval):\n",
    "    return sigmaval * np.exp(-dist/rangeval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculer la matrice de distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat=abs(np.subtract.outer(discretization,discretization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculer la matrice de covariance du vecteur $\\mathbf{Z}=(Z(x_0),\\dots,Z(x_N))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma=Covexp(distmat,a,sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extraire les 3 matrices de covariance suivantes :\n",
    "\n",
    " * entre les observations\n",
    "\n",
    " * entre les observations et les inconnues\n",
    "\n",
    " * entre les inconnues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SigmaObs = Sigma[observation_indexes,:][:,observation_indexes]\n",
    "SigmaObsUnknown = Sigma[observation_indexes,:][:,unknown_indexes]\n",
    "SigmaUnknown = Sigma[unknown_indexes,:][:,unknown_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculer l'esp√©rance conditionnelle des composantes non observ√©es connaissant les observations et la repr√©senter avec les donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invSigma = np.linalg.inv(SigmaObs) \n",
    "Ec= mu+np.matmul(np.transpose(SigmaObsUnknown),np.matmul(np.linalg.inv(SigmaObs),depth-mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allval1 = np.zeros(N)\n",
    "allval1[unknown_indexes]=Ec\n",
    "allval1[observation_indexes]=depth\n",
    "plt.plot(discretization,allval1)\n",
    "plt.plot(discretization[observation_indexes], depth, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calculer la matrice de variance conditionnelle et tracer sa diagonale (variance conditionnelle) en fonction de la position. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SigmaCond = SigmaUnknown - np.matmul(np.transpose(SigmaObsUnknown),np.matmul(np.linalg.inv(SigmaObs),SigmaObsUnknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allval2 = np.zeros(N)\n",
    "allval2[unknown_indexes]=np.diag(SigmaCond)\n",
    "plt.plot(discretization,allval2)\n",
    "plt.plot(discretization[observation_indexes], np.zeros(np.shape(observation_indexes)[0]), 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*On voit ici que la variance est nulle aux points de donn√©es (puisque la valeur est fix√©e) puis qu'elle augmente lorsqu'on s'√©loigne des donn√©es*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Effectuer une simulation conditionnelle. Sur un m√™me graphique, tracer la simulation ainsi que les donn√©es et l'esp√©rance conditionnelle. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cholesky = np.linalg.cholesky(SigmaCond)\n",
    "x = np.random.normal(0,1,np.shape(unknown_indexes)[0])\n",
    "simu = Ec + np.matmul(Cholesky,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allval3 = np.zeros(N)\n",
    "allval3[unknown_indexes]=simu\n",
    "allval3[observation_indexes]=depth\n",
    "plt.plot(discretization,allval3)\n",
    "plt.plot(discretization,allval1)\n",
    "plt.plot(discretization[observation_indexes], depth, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*l'esp√©rance conditionnelle est lisse car c'est la fonction des donn√©es qui minimise la variance ; la simulation conditionnelle reproduit les fluctuations du mod√®le et donc l'aspect du fond marin*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Ecrire une fonction qui calcule la longueur du c√¢ble en fonction du vecteur des profondeurs et du pas de discr√©tisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(z,delta):\n",
    "    return sum(np.sqrt(Delta**2+(z[1:N]-z[0:-1])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Utiliser cette fonction pour calculer la longueur du c√¢ble √† partir de 100 simulations. Comparer l'esp√©rance conditionnelle (estim√©e) de la longueur avec la longueur de l'esp√©rance conditionnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=100000\n",
    "result = np.zeros(K)\n",
    "for i in range(K):\n",
    "    x=np.random.normal(0,1,np.shape(unknown_indexes)[0])\n",
    "    allval3[unknown_indexes]=Ec + np.matmul(Cholesky,x)\n",
    "    result[i]=length(allval3,Delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(result)/K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(allval1,Delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*On donne ici directement les r√©sultats pour 100000 simulations (comparer la vitesse d'√©x√©cution avec votre code pour voir l'int√©r√™t de la vectorisation).*\n",
    "\n",
    "*On voit ici que la longueur donn√©e par l'esp√©rance conditionnelle est bien moindre que la longueur d'une simulation conditionnelle. Ceci est d√ª au fait que la simulation conditionnelle va reproduire les fluctuations attendues, au contraire de l'esp√©rance conditionnelle qui minimise la variance.*\n",
    "\n",
    "*NB : On remarquera que c'est le seul endroit o√π on a utilis√© une boucle dans cette correction. On aurait pu s'en passer en utilisant notamment les outils de la librairie Pandas mais le code est plus lisible ainsi.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Repr√©senter la suite $M_n$ des moyennes des longueurs de c√¢bles en fonction du nombre de simulations. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_simu = 1+np.arange(K)\n",
    "plt.plot(indice_simu,np.cumsum(result)/indice_simu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comme attendu d'apr√®s la LFGN, on observe une stabilisation de la valeur moyenne. Les variations sont imperceptibles apr√®s quelques dizaines de milliers de simulations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Repr√©senter l'histogramme des longueurs de c√¢bles g√©n√©r√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(result,50,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L'histogramme ressemble √† une densit√© gaussienne, avec n√©anmoins une l√©g√®re dissym√©trie (plus de valeurs fortes).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Donner un intervalle de confiance √† 95% de la longueur du c√¢ble par 2 m√©thodes diff√©rentes. Commenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1√®re m√©thode : par approximation gaussienne. L'histogramme pr√©c√©dent sugg√®re qu'une loi gaussienne peut bien repr√©senter la loi conditionnelle de la longueur du cable. On obtient un intervalle de confiance en calculant la moyenne (milieu de l'intervalle) et l'√©cart type de l'√©chantillon de longueurs de c√¢ble puis en appliquant la formule du cours.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ln = sum(result)/K\n",
    "sigman = np.std(result)\n",
    "[Ln - sigman*1.96,Ln + sigman*1.96]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2e m√©thode : on extrait les quantiles √† 2.5% et 97.5% de l'√©chantillon, c'est-√†-dire les valeurs $x_\\alpha$ pour $\\alpha \\in \\{0.025 ; 0.975\\}$telles que* $$\\mathbb{P}(L<x_\\alpha) \\approx \\frac{1}{n}\\sum_{i=1}^N 1_{\\{L_i<x_\\alpha\\}}$$"
   ]
  },
  {
   "source": [
    "np.quantile(result,[0.025,0.975])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ATTENTION : ici l'utilisation du TCL tel qu'expos√© au d√©but du chapitre 5 fournissait un intervalle de confiance de l'**esp√©rance de la longueur de c√¢ble** et non de la **longueur de c√¢ble** (erreur fr√©quente).*\n",
    "\n",
    "*On voit par ailleurs que la 2e m√©thode est plus pr√©cise car elle est bas√©e directement sur la loi empirique de l'√©chantillon*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Donner une estimation de la probabilit√© que la longueur du c√¢ble d√©passe 525 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(result>525)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Reprendre les questions pr√©c√©dentes avec 1000, 10000 puis 100000 simulations. Commenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*cf. le commentaire de la question 10. On observe une stabilisation progressive des estimateurs des diff√©rentes quantit√©s calcul√©es : moyennes, quantiles, probabilit√© de d√©passement de seuil.*"
   ]
  },
  {
   "source": [
    "# Enonc√© 2021 (Partie 2)\n",
    "\n",
    "Nous nous pla√ßons dans le m√™me cadre que ci-dessus. Nous tenons pour acquis les r√©sultats pr√©c√©dents et allons maintenant approfondir l'analyse."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Valeurs positives\n",
    "\n",
    "1. A la question 7 de la partie 1, on peut s'apercevoir que certains profils de profondeur pr√©sentent des valeurs positives, ce qui n'a pas de sens si on consid√®re qu'il n'y a pas de partie √©merg√©e entre les deux c√¥tes. Proposer et impl√©menter un algorithme de type rejet qui ne g√©n√®rera que des valeurs n√©gatives. Repr√©senter un profil de profondeur g√©n√©r√©."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"La matrice Cholesky √©tant triangulaire inf√©rieure, la profondeur simul√©e √† une abscisse i d√©pend des variables al√©atoires x[j] pour j allant de 0 √† i, o√π x est le vecteur gaussien utilis√© en premi√®re partie. Si i est l'abscisse minimale pour laquelle la profondeur est positive, il suffit alors de recalculer x[i] sans modifier les x[j] avec 0<=j<i\"\"\"\n",
    "\n",
    "n = np.shape(unknown_indexes)[0]\n",
    "x = np.random.normal(0,1,np.shape(unknown_indexes)[0])\n",
    "for i in range(n):\n",
    "    while Ec[i] + np.matmul(Cholesky,x)[i] >= 0 :\n",
    "        x[i] = np.random.normal(0,1)\n",
    "simu = Ec + np.matmul(Cholesky,x)\n",
    "\n",
    "allval4 = np.zeros(N)\n",
    "allval4[unknown_indexes]=simu\n",
    "allval4[observation_indexes]=depth\n",
    "plt.plot(discretization,allval1, label = 'moyenne conditionnelle')\n",
    "plt.plot(discretization,allval4, label = 'simulation')\n",
    "plt.label()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "2. L'emploi de cet algorithme a-t-il un impact sur la valeur moyenne de la longueur de c√¢ble ? Sur l'histogramme des longueurs de c√¢ble ? Sur l'intervalle de confiance obtenu par la m√©thode des quantiles ? Sur la probabilit√© de d√©passement du seuil de 525 m? Donner une estimation du taux de rejet de l'algorithme. Consid√©rer 10000 simulations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=10000\n",
    "result = np.zeros(K)\n",
    "result_rejet = np.zeros(K)\n",
    "rejet = np.zeros(K)\n",
    "for i in range(K):\n",
    "    t_rejet = 0\n",
    "    n_iter = 101\n",
    "    x=np.random.normal(0,1,np.shape(unknown_indexes)[0])\n",
    "    allval3[unknown_indexes]= Ec + np.matmul(Cholesky,x)\n",
    "    result[i] = length(allval3,Delta)\n",
    "    x_rejet = x\n",
    "    for j in range(n):\n",
    "        while Ec[j] + np.matmul(Cholesky,x_rejet)[j] >= 0 :\n",
    "            x_rejet[j] = np.random.normal(0,1)\n",
    "            t_rejet += 1\n",
    "            n_iter += 1\n",
    "    allval4[unknown_indexes] = Ec + np.matmul(Cholesky,x_rejet)\n",
    "    result_rejet[i]=length(allval4,Delta)\n",
    "    rejet[i] = t_rejet/n_iter\n",
    "\n",
    "print(f\"taux de rejet : {sum(rejet)/K}\")\n",
    "print(f\"intervalle de confiance sans rejet : {np.quantile(result,[0.025,0.975])}\")\n",
    "print(f\"intervalle de confiance avec rejet : {np.quantile(result_rejet,[0.025,0.975])}\")\n",
    "print(f\"probabilit√© de d√©passement du seuil sans rejet : {np.mean(result>525)}\")\n",
    "print(f\"probabilit√© de d√©passement du seuil avec rejet : {np.mean(result_rejet>525)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Comparaison des histogrammes\"\"\"\n",
    "\n",
    "plt.hist(result,50,density=True, label = 'sans rejet')\n",
    "plt.hist(result_rejet,50,density=True, label = 'avec rejet')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Comparaison des valeurs moyennes\"\"\"\n",
    "\n",
    "indice_simu = 1+np.arange(K)\n",
    "plt.plot(indice_simu,np.cumsum(result)/indice_simu, label = 'sans rejet')\n",
    "plt.plot(indice_simu,np.cumsum(result_rejet)/indice_simu, label = 'avec rejet')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "On observe que la longueur du c√¢ble est en moyenne amoindrie d'environ un m√®tre. L'intervalle de confiance et l'histogramme sont donc d√©plac√©s dans ce sens et la probabilit√© de d√©passement du seuil diminue."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Approche Bay√©sienne\n",
    "\n",
    "Dans la premi√®re partie, on a consid√©r√© que l'ensemble des param√®tres du mod√®le √©tait parfaitement connu. Toutes choses √©gales par ailleurs, on va maintenant consid√©rer que la moyenne $\\mu$ est issue d'une estimation ent√¢ch√©e d'une incertitude. Plus pr√©cis√©ment, on va mod√©liser cette incertitude en consid√©rant que $\\mu \\sim \\mathcal{N}(-5,4)$.\n",
    "\n",
    "On va √©galement d√©composer le vecteur $\\mathbf{Z}$ en $\\mathbf{Z} = (\\mathbf{Z}_{\\text{OBS}},\\mathbf{Z}_{\\text{UNK}})$. On notera $C_{\\text{OBS}}$ et $C_{\\text{UNK}}$ les matrices de covariance respectives de $\\mathbf{Z}_{\\text{OBS}}$ et $\\mathbf{Z}_{\\text{UNK}}$ ainsi que $C_{\\text{OBS},\\text{UNK}}$ la matrice des covariances entre ces deux vecteurs.\n",
    "\n",
    "### Questions th√©oriques\n",
    "\n",
    "3. Montrer que $\\mu | \\mathbf{Z}_{\\text{OBS}}= \\mathbf{z}_{\\text{OBS}} \\sim \\mathcal{N}(\\widehat{\\mu},\\widehat{\\sigma}^2)$ avec\n",
    "$$\\widehat{\\sigma}^2 = (\\mathbf{1}^t C_{\\text{OBS}}^{-1} \\mathbf{1} + \\frac1{4})^{-1},$$ \n",
    "o√π $\\mathbf{1}$ est un vecteur de longueur 6 (soit la longueur du vecteur $\\mathbf{Z}_{\\text{OBS}}$) ne contenant que des 1 et \n",
    "$$\\widehat{\\mu} = \\widehat{\\sigma}^2 (\\mathbf{1}^t C_{\\text{OBS}}^{-1} \\mathbf{z}_{\\text{OBS}} - \\frac{5}{4} )$$\n",
    "Indication : √©crire la densit√© jointe du vecteur $(\\mathbf{Z}_{\\text{OBS}},\\mu)$, calculer $-2 \\ln$ de cette densit√© puis identifier la forme quadratique faisant intervenir $\\mu$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "On va calculer la densit√© $f_{\\mu | Z_{OBS}=z_{OBS}}$ gr√¢ce √† la formule de Bayes, selon laquelle on a pour tous $\\nu \\in \\mathbb{R}$, $z_{OBS} \\in \\mathbb{R}^6$:\n",
    "\n",
    "$$ f_{\\mu | Z_{OBS}=z_{OBS}}(\\nu)f_{Z_{OBS}}(z_{OBS}) = f_{Z_{OBS} | \\mu=\\nu}(z_{OBS})f_{\\mu}(\\nu)$$\n",
    "\n",
    "Soit $z_{OBS} \\in \\mathbb{R}^6$. On a, par formule du balayage conditionnel :\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{Z_{OBS}}(z_{OBS}) &= \\int_{\\mathbb{R}} f_{Z_{OBS} | \\mu=\\nu}(z_{OBS})f_{\\mu}(\\nu) \\, \\mathrm{d}\\nu\\\\\n",
    "&= \\int_{\\mathbb{R}} \\left(\\frac{1}{(2\\pi)^6\\sqrt{det(C_{OBS})}}e^{-\\frac{1}{2}(z_{OBS} - \\nu\\cdot1)^TC_{OBS}^{-1}(z_{OBS} - \\nu\\cdot1)}\\right)\\left(\\frac{1}{2\\sqrt{2\\pi}}e^{-\\frac{(\\nu + 5)^2}{8}}\\right) \\, \\mathrm{d}\\nu \\\\\n",
    "&= \\int_{\\mathbb{R}} \\frac{1}{2(2\\pi)^{\\frac{7}{2}}\\sqrt{det(C_{OBS})}}e^{-\\frac{1}{2}\\left((1^TC_{OBS}^{-1}1 + \\frac{1}{4})\\nu^2 + (\\frac{5}{2} - 2\\cdot1^TC_{OBS}^{-1}z_{OBS})\\nu + (z_{OBS}^TC_{OBS}^{-1}z_{OBS} + \\frac{25}{4})\\right)} \\, \\mathrm{d}\\nu \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "On pose : \n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "K = \\dfrac{1}{2(2\\pi)^{\\frac{7}{2}}\\sqrt{det(C_{OBS})}} \\\\ \n",
    "A = 1^TC_{OBS}^{-1}1 + \\dfrac{1}{4} \\\\ \n",
    "B = \\dfrac{5}{2} - 2\\cdot1^TC_{OBS}^{-1}z_{OBS}\\\\  \n",
    "C = z_{OBS}^{T}C_{OBS}^{-1}z_{OBS} + \\dfrac{25}{4}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "De telle sorte qu'on ait :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{Z_{OBS}}(z_{OBS}) &= K \\int_{\\mathbb{R}} e^{-\\frac{1}{2}\\left(A\\nu^2 + B\\nu + C\\right)} \\, \\mathrm{d}\\nu \\\\\n",
    "&= K \\int_{\\mathbb{R}} e^{-\\frac{A}{2}\\left((\\nu + \\frac{B}{2A})^2 + \\frac{C}{A} - \\frac{B^2}{4A^2}\\right)} \\, \\mathrm{d}\\nu \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Par le changement de variable $ u = \\sqrt{\\dfrac{A}{2}}\\left(\\nu + \\dfrac{B}{2A}\\right)$, on obtient :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{Z_{OBS}}(z_{OBS}) &= K\\sqrt{\\dfrac{2}{A}}e^{-\\frac{C - \\frac{B^2}{4A}}{2}}\\int_{\\mathbb{R}} e^{-u^2} \\, \\mathrm{d}u\\\\\n",
    "&= K\\sqrt{\\dfrac{2\\pi}{A}}e^{-\\frac{C - \\frac{B^2}{4A}}{2}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Soit √©galement $\\nu \\in \\mathbb{R}$. On a alors, par formule de Bayes :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{\\mu | Z_{OBS}=z_{OBS}}(\\nu)\\cdot K\\sqrt{\\dfrac{2\\pi}{A}}e^{-\\frac{C - \\frac{B^2}{4A}}{2}} &= f_{Z_{OBS} | \\mu=\\nu}(z_{OBS})f_{\\mu}(\\nu)\\\\\n",
    "&= K e^{-\\frac{1}{2}\\left(A\\nu^2 + B\\nu + C\\right)} \\text{, d'apr√®s le calcul pr√©c√©dent} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Alors :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{\\mu | Z_{OBS} = z_{OBS}}(\\nu) &= \\sqrt{\\dfrac{A}{2\\pi}}e^{-\\frac{1}{2}\\left(A\\nu^2 + B\\nu + C + \\frac{B^2}{4A} - C\\right)}\\\\\n",
    "&= \\sqrt{\\dfrac{A}{2\\pi}}e^{-\\frac{A}{2}\\left(\\nu^2 + \\frac{B}{A}\\nu + (\\frac{B}{2A})^2\\right)}\\\\\n",
    "&= \\sqrt{\\dfrac{A}{2\\pi}}e^{-\\frac{A}{2}\\left(\\nu + \\frac{B}{2A}\\right)^2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "On obtient le r√©sultat escompt√© en posant $ \\widehat\\sigma^2 = \\dfrac{1}{A} = \\dfrac{1}{1^TC_{OBS}^{-1}1 + \\dfrac{1}{4}}$ et $\\widehat\\mu = -\\dfrac{B}{2A} =  \\widehat\\sigma^2 \\cdot \\left(1^TC_{OBS}^{-1}z_{OBS} - \\dfrac{5}{4}\\right)$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "4. Montrer que si $X$, $Y$ et $Z$ sont trois vecteurs al√©atoires √† densit√©, alors $f_{X,Y|Z = z}(x,y) = f_{X|Y=y,Z=z}(x)f_{Y|Z=Z}(y)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Soient X, Y, et Z trois vecteurs al√©atoires √† densit√© √† $n_X$, $n_Y$ et $n_Z$ dimensions respectivement. Pour tous $x \\in \\mathbb{R}^{n_X}$, $y \\in \\mathbb{R}^{n_Y}$, $z \\in \\mathbb{R}^{n_Z}$ tels que $f_Y(y) \\neq 0$ et $f_Z(z) \\neq 0$ :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{(X,Y)|Z = z}(x,y) &= \\dfrac{f_{(X, Y, Z)}(x, y, z)}{f_Z(z)} \\\\\n",
    "&= \\dfrac{f_{X|(Y, Z) = (y, z)}(x)\\cdot f_{(Y, Z)}(y, z)}{f_Z(z)}\\\\\n",
    "&= f_{X|Y = y, Z = z}(x)\\cdot f_{Y|Z=z}(y)\n",
    "\\end{align*}\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "5. En d√©duire que la densit√© de $(\\mathbf{Z}_{\\text{UNK}},\\mu) | \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}$ s'√©crit comme le produit de $f_{\\mu | \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}}$ et de $f_{\\mathbf{Z}_{\\text{UNK}}| \\mu = \\mu^\\star, \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}}$ que l'on exprimera.\n",
    "\n",
    "    Indication : $f_{\\mathbf{Z}_{\\text{UNK}}| \\mu = \\mu^\\star, \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}}$ est identique √† la densit√© $f_{\\mathbf{Z}_{\\text{UNK}}| \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}}$ utilis√©e dans la partie 1 avec $\\mu = \\mu^\\star$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "En appliquant ce qui pr√©c√®de aux vecteurs al√©atoires √† densit√© $Z_{UNK}$, $\\mu$ et $Z_{OBS}$, on obtient :\n",
    "\n",
    "$$f_{Z_{UNK},\\mu|Z_{OBS} = z_{OBS}} = f_{Z_{UNK}|\\mu=\\mu^*,Z_{OBS} = z_{OBS}}\\cdot f_{\\mu|Z_{OBS} = z_{OBS}}(\\mu^*)$$\n",
    "\n",
    "On a alors, d'apr√®s le cours, pour tout $z_{UNK} \\in \\mathbb{R}^{95}$ :\n",
    "\n",
    "$f_{Z_{UNK}|\\mu=\\mu^*,Z_{OBS} = z_{OBS}}(z_{UNK}) = \\dfrac{1}{(2\\pi)^{\\frac{95}{2}}\\sqrt{det(CS_{Z_{UNK}})}}\\cdot e^{(z_{UNK} - \\psi(z_{OBS}))^TCS_{Z_{UNK}}^{-1}(z_{UNK} - \\psi(z_{OBS}))}$\n",
    "\n",
    "Avec \n",
    "\n",
    "$$ CS_{Z_{UNK}} = C_{UNK} - C_{UNK, OBS}C_{OBS}^{-1}C_{UNK, OBS}^T$$\n",
    "\n",
    "et\n",
    "\n",
    "$$ \\psi(z_{OBS}) = \\mu^*\\cdot 1_{95} + C_{UNK, OBS}C_{OBS}^{-1}(z_{OBS} - \\mu^*\\cdot 1_{6})$$\n",
    "\n",
    "o√π $1_{95}$ et $1_{6}$ sont les vecteurs de dimensions respectives 95 et 6 ne contenant que des 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Simulation\n",
    "\n",
    "On va maintenant chercher √† simuler les valeurs de $\\mathbf{Z}_{\\text{UNK}}$ en tenant compte de l'incertitude sur $\\mu$.\n",
    "\n",
    "En premi√®re approche, on pourrait chercher √† obtenir la densit√© de $\\mathbf{Z}_{\\text{UNK}} | \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}$ en calculant \n",
    "$$\\int_\\mathbb{R} f_{(\\mathbf{Z}_{\\text{UNK}},\\mu) | \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}}(\\mathbf{z}_{\\text{UNK}},\\mu^\\star) d\\mu^\\star$$\n",
    "mais ce calcul a peu de chances d'aboutir.\n",
    "\n",
    "On va plut√¥t proc√©der par simulations en cascade, c'est-√†-dire que pour chaque simulation de $\\mathbf{Z}_{\\text{UNK}}$, on va d'abord g√©n√©rer une valeur $\\mu^\\star$ de $\\mu$ selon $f_{\\mu | \\mathbf{Z}_{\\text{OBS}}= \\mathbf{z}_{\\text{OBS}}}$ puis on simulera $\\mathbf{Z}_{\\text{UNK}}$ selon $f_{\\mathbf{Z}_{\\text{UNK}}| \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}},\\mu = \\mu^\\star}$.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "6. Calculer $\\widehat{\\mu}$ et $\\widehat{\\sigma}^2$. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = np.ones(6) #vecteur de 1\n",
    "val = np.matmul (np.transpose(vec1), np.matmul(np.linalg.inv(SigmaObs), vec1) )\n",
    "sigc2 = 1/(val+0.25) \n",
    "print(sigc2) #sigma chapeau carr√©\n",
    "\n",
    "\n",
    "muc = sigc2 * (np.matmul (np.transpose(vec1), np.matmul(np.linalg.inv(SigmaObs), depth) ) - 5/4 )\n",
    "print(muc) #mu chapeau"
   ]
  },
  {
   "source": [
    "7. Calculer la probabilit√© de $\\{\\mu| \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}} > 0\\}$. Proposer et impl√©menter un algorithme de simulation de $\\mu| \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}, \\mu <0$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(ùúá|ùêôOBS=ùê≥OBS>0) = 1 - F(0)\n",
    "import scipy.stats\n",
    "proba = 1 - scipy.stats.norm(muc, sigc2).cdf(0) #cdf = cumulative distribution function = fonction de r√©partition\n",
    "print(f\"P( ùúá|ùêôOBS=ùê≥OBS > 0 ) = {round(proba, 4)}\")\n",
    "\n",
    "\n",
    "x = np.linspace(loi.ppf(0.01),\n",
    "                loi.ppf(0.99), 100)\n",
    "plt.plot(x, loi.pdf(x))\n",
    "\n",
    "def simumu():\n",
    "    for i in range(5):\n",
    "        x = np.random.normal(muc, sigc2)\n",
    "        if ( x<0 ):\n",
    "            return x\n",
    "    else:\n",
    "        raise ValueError(f\"no convergence in 5 steps.\")\n",
    "\n",
    "print(simumu())"
   ]
  },
  {
   "source": [
    "8. G√©n√©rer un couple $\\mathbf{Z}_{\\text{UNK}}, \\mu| \\mathbf{Z}_{\\text{OBS}}, \\mu <0$ et repr√©senter le profil de profondeur obtenu. On prendra soin de ne g√©n√©rer que des valeurs n√©gatives de $\\mathbf{Z}_{\\text{UNK}}$ en utilisant l'algorithme de la section pr√©c√©dente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = simumu()\n",
    "#Zunk = AlgoQ1()"
   ]
  },
  {
   "source": [
    "9. G√©n√©rer 10000 profils de profondeur et calculer les longueurs de c√¢ble associ√©es. Comparer la valeur moyenne de la longueur de c√¢ble, dont on visualisera la convergence, l'histogramme des longueurs de c√¢ble, l'intervalle de confiance obtenu par la m√©thode des quantiles, la probabilit√© de d√©passement du seuil de 525 m avec les r√©sultats obtenus pr√©c√©demment. Commenter."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "10. Qu'adviendrait-il selon vous si on rendait √©galement al√©atoires les autres param√®tres du mod√®le $\\sigma^2$ et $a$ ?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "11. (facultatif) On suppose d√©sormais que $\\alpha = \\frac1{\\sigma^2} \\sim \\Gamma(a_1,a_2)$, o√π $\\sigma^2$ correspond au param√®tre qui intervient dans la fonction $C$. Donner l'expression de la densit√© de $\\alpha | \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}$,  de $\\mu | \\alpha, \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}},$ et de $\\mathbf{Z}_{\\text{UNK}} | \\mu, \\alpha, \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}$. Proposer un algorithme de simulation tenant compte de l'incertitude sur le param√®tre $\\alpha$ et analyser son impact sur les diff√©rentes quantit√©s √©valu√©es.\n",
    "\n",
    "    Indication : Pour identifier la densit√© de $\\alpha | \\mathbf{Z}_{\\text{OBS}} = \\mathbf{z}_{\\text{OBS}}$, exprimer d'abord la densit√© jointe de $(\\alpha,\\mu, \\mathbf{Z}_{\\text{OBS}})$ puis marginaliser pour obtenir la densit√© de $(\\alpha,\\mathbf{Z}_{\\text{OBS}})$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "5ceb69a5bbd14071b254c2439a58ac4b",
   "lastKernelId": "0e923419-c540-42c1-ab5f-d0e05ff4521c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f33ae800dd2568c40b936dedf002915d562a8c328113d032903aa4a6117d0b36"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}